# No bang for your buck? On accuracy incentives in expectation aggregation

Due to the absence or cost of acquiring relevant historical data, many forecasting questions are answered by soliciting and aggregating the expectations of stakeholders. Prediction markets offer a particularly systematic way of doing just that, which moreover tends to yield accurate outputs. A common explanation for this is that such markets incentivise  accuracy. However, the present paper reports on an experimental study involving participants being asked to perform two estimation tasks, mirroring the two main incentive structures on prediction markets, and finds minimal differences in accuracy on each task compared to a control condition. This calls into question the idea that prediction markets are successful on account of their incentive structure. Instead, it is argued that such markets are best understood as a special case of so-called expectation polls --- polls or surveys asking people about participants’ expectations (e.g., “Who will win the election?”) as opposed to about their intentions (e.g., “How would you vote, if there were an election today?”) --- and that one plausible explanation for the relative success of prediction markets is at least partly that they ask the right type of question: a predictive question, tapping into respondents’ expectations rather than their intentions or preferences.